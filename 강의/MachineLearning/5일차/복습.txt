머신러닝의 종류
1.지도학습: 레이블 존재
    -분류: 레이블이 범주형 변수임 - 이 데이터의 다음 데이터를 알 수 있음(1다음엔 2) - 정확도
            -KNN: 기하모델, 비선형, HP: K, 장점: 직관적/학습이 빠름 ,단점: 예측이 느림(Lazy Algorithm) 
            -로지스틱 회귀: 기하, 선형, HP: c(규제강도) or max_iter(경사하강법을 수렴시키기 위해 반복학습할 횟수를 정해줌), 
                           장점: 직관적/회귀모델과 호환 가능/조건 맞으면 강력, 단점: 선형전제를 간주/이진분류만 가능(->sofrmax, ovo,ovr 고려)  
            -의사결정나무: 확률, (선형을 따지는 것을 의미가 없음), HP: max_depth, max_leaf_nodes...
                          장점: 조율 할게 많음/조건 필요없음/평타는 침
                          단점: 과대적합 위험도가 큼(예외처리방법이 없기때문)
                                <해결책>
                                -보팅(voting)
                                -배깅(bagging): HP의 종류가 많기 때문에 랜덤으로 HP을 생성? ->과대적합을 해결하기 위해서 우선적으로 고려함
                                    -RandomForest
                                
                                -부스팅(boosting): 이전의 HP를 기반으로 더 나은 HP를 생성해 나감(마치 경사하강법같이) 
                                    -Adu, Gradient, XG, Light gbm 
    -회귀: 레이블이 연속형 변수임 - 0 다음엔 0.1도 있고 0.01도 있어서 알 수 없음 - mse
            -선형회귀: 기하, 선형, HP: 없음, 장점: 직관적/세대간 소통이 가능, 단점: 과대적합시 조율방법이 존재하지 않음, 선형전제를 가져야 함.
            -Ridge/Lasso: 기하, 선형, HP: 알파(규제강도), 장점: 조건이 맞으면 강력, 단점: 선형전제를 가져야 함.
                정규성: 선(그래프)를 기준으로 정규분포를 따르는 상태 선과 멀어질수로 약해지는 상태? 
                등분산성: 모든 구간에서 등산이 일정하게 퍼지는 상태
                독립성: 다른요인에 의해서 종속변수가 영향을 받으면 안된다

    기하모델: 데이터를 좌표평면에 표기 - scaling 요구
            -선형: 독립변수x로 인해서 종속변수y가 정해진다(유의미한 상관관계가 존재)
            -비선형
    확률모델: 동시출현 확률 - scaling 요구x

2.비지도 학습: 레이블 존재x
3.강화학습: 보상으로써 레이블이 존재
4.오토인코더: input 그자체가 레이블이 됨
