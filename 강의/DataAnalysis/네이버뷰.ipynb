{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities #다음화면으로 빨리 넘어갈때\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException #selenium 이용시 Alert을 제어\n",
    "import urllib.request\n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#크롤링 시작과 끝 날짜(달 별로 크롤링)\n",
    "#                                                        각 달의 첫날\n",
    "first_days=pd.date_range('2021/01/01', '2021/01/31', freq='MS')\n",
    "#                                                        각 달의 마지막 날\n",
    "last_days=pd.date_range('2021/01/01', '2021/01/31', freq='M')\n",
    "\n",
    "#검색 키워드 추가\n",
    "keyword_list=['이수역맛집', '점심']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬드라이버 제어\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox') #bypass OS security model\n",
    "chrome_options.add_argument('--disable-dex-shm-usage')#overcome limited resource problems\n",
    "# options.add_argument('--headless') # 브라우저 백그라운드 모드\n",
    "\n",
    "\n",
    "chrome_path = 'chromedriver.exe' #현재 컴퓨터의 크롬드라이버 위치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11584\\2598069413.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path = chrome_path, chrome_options=chrome_options)\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=107.0.5304.107)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\develops\\DataAnalysis\\네이버뷰.ipynb 셀 4\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/develops/DataAnalysis/%EB%84%A4%EC%9D%B4%EB%B2%84%EB%B7%B0.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/develops/DataAnalysis/%EB%84%A4%EC%9D%B4%EB%B2%84%EB%B7%B0.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m url_want \u001b[39m=\u001b[39m \u001b[39m990\u001b[39m \u001b[39m#\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/develops/DataAnalysis/%EB%84%A4%EC%9D%B4%EB%B2%84%EB%B7%B0.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m driver\u001b[39m.\u001b[39;49mfind_element(\u001b[39m'\u001b[39;49m\u001b[39mxpath\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msnb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]/div[1]/div/div[2]/a\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mclick() \u001b[39m#검색 옵션 클릭\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/develops/DataAnalysis/%EB%84%A4%EC%9D%B4%EB%B2%84%EB%B7%B0.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# 날짜 지정\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/develops/DataAnalysis/%EB%84%A4%EC%9D%B4%EB%B2%84%EB%B7%B0.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(first_days)):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:976\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m         by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    975\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[1;32m--> 976\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m'\u001b[39;49m: by,\n\u001b[0;32m    978\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m: value})[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:321\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 321\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    322\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[0;32m    323\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:242\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)\n\u001b[1;32m--> 242\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=107.0.5304.107)\n"
     ]
    }
   ],
   "source": [
    "# 블로그 주소 수집\n",
    "\n",
    "blog_url_list = []\n",
    "\n",
    "# 네이버에 키워드 검색\n",
    "for keyword in keyword_list:\n",
    "    url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=blog&query={}&oquery={}'.format(keyword, keyword)\n",
    "    driver = webdriver.Chrome(executable_path = chrome_path, chrome_options=chrome_options)\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    url_want = 990 #\n",
    "    \n",
    "    driver.find_element('xpath','//*[@id=\"snb\"]/div[1]/div/div[2]/a').click() #검색 옵션 클릭\n",
    "    \n",
    "    # 날짜 지정\n",
    "    for k in range(len(first_days)):\n",
    "        try:\n",
    "            # 시작과 끝의 년월일 설정\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[1]/a[9]/i').click() #직접 입력\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(first_days.year[k]-2002)).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(first_days.month[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(first_days.day[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[1]/span[3]/a').click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(last_days.year[k]-2002)).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(last_days.month[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(last_days.day[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[3]/button').click()\n",
    "            \n",
    "            # 스크롤 조작\n",
    "            last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "            \n",
    "            scroll = (url_want/30)-1 # 한 페이지에 기본으로 30개 글이 나옴\n",
    "            \n",
    "            # 스크롤 다운\n",
    "            for i in range(int(scroll)):\n",
    "                driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "                # 0부터 연재까지의 스크롤 좌표를 가져와 줘의 의미\n",
    "                time.sleep(random.uniform(1, 1.7))\n",
    "                \n",
    "                new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "                \n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                \n",
    "                last_height = new_height\n",
    "                \n",
    "            soup = bs(driver.page_source, 'lxml')\n",
    "            blog_url = soup.find_all('a', class_='api_txt_lines total_tit')\n",
    "            \n",
    "            # url 주소 수집\n",
    "            for i in blog_url:\n",
    "                blog_url_list.append(i['href']) # 주소 수집\n",
    "            \n",
    "            print('{0} 키워드 {1}년 {2}월'.format(keyword, first_days.year[k], first_days.month[k]), len(blog_url), '개 블로그 url 주소 수집')\n",
    "            \n",
    "            driver.execute_script('window.scrollTo(0,0)')\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수집 후 url list 중복 확인 810+990\n",
    "real_list = set(blog_url_list)\n",
    "blog_url_list = list(real_list)\n",
    "len(blog_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 저장(블로그 주소)\n",
    "k = pd.DataFrame(blog_url_list)\n",
    "#\n",
    "k.to_csv('url_list_맛집.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "url=pd.read_csv('url_list_맛집.csv')\n",
    "blog_url_list = list(url['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5768\\3172629000.py:13: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options) #크롬 드라이버 위치만 바꿔주시면 됩니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://mintmant.tistory.com/55\n",
      "20개 블로그 크롤링 완료\n",
      "30개 블로그 크롤링 완료\n",
      "40개 블로그 크롤링 완료\n",
      "50개 블로그 크롤링 완료\n",
      "60개 블로그 크롤링 완료\n",
      "70개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://felkmt.tistory.com/4157\n",
      "80개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://gqinside.tistory.com/412\n",
      "90개 블로그 크롤링 완료\n",
      "100개 블로그 크롤링 완료\n",
      "110개 블로그 크롤링 완료\n",
      "120개 블로그 크롤링 완료\n",
      "130개 블로그 크롤링 완료\n",
      "140개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://mintmant.tistory.com/60\n",
      "150개 블로그 크롤링 완료\n",
      "160개 블로그 크롤링 완료\n",
      "170개 블로그 크롤링 완료\n",
      "180개 블로그 크롤링 완료\n",
      "190개 블로그 크롤링 완료\n",
      "200개 블로그 크롤링 완료\n",
      "210개 블로그 크롤링 완료\n",
      "220개 블로그 크롤링 완료\n",
      "230개 블로그 크롤링 완료\n",
      "240개 블로그 크롤링 완료\n",
      "250개 블로그 크롤링 완료\n",
      "260개 블로그 크롤링 완료\n",
      "270개 블로그 크롤링 완료\n",
      "280개 블로그 크롤링 완료\n",
      "290개 블로그 크롤링 완료\n",
      "300개 블로그 크롤링 완료\n",
      "310개 블로그 크롤링 완료\n",
      "320개 블로그 크롤링 완료\n",
      "330개 블로그 크롤링 완료\n",
      "340개 블로그 크롤링 완료\n",
      "350개 블로그 크롤링 완료\n",
      "360개 블로그 크롤링 완료\n",
      "370개 블로그 크롤링 완료\n",
      "380개 블로그 크롤링 완료\n",
      "390개 블로그 크롤링 완료\n",
      "400개 블로그 크롤링 완료\n",
      "410개 블로그 크롤링 완료\n",
      "420개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://mforu.tistory.com/721\n",
      "430개 블로그 크롤링 완료\n",
      "440개 블로그 크롤링 완료\n",
      "450개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://chandori11.tistory.com/202\n",
      "네이버 블로그 아닌 url:  https://issuetoktok1177.tistory.com/90\n",
      "460개 블로그 크롤링 완료\n",
      "470개 블로그 크롤링 완료\n",
      "480개 블로그 크롤링 완료\n",
      "490개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://jabssul.tistory.com/70\n",
      "500개 블로그 크롤링 완료\n",
      "510개 블로그 크롤링 완료\n",
      "520개 블로그 크롤링 완료\n",
      "네이버 블로그 아닌 url:  https://issuetoktok1177.tistory.com/89\n",
      "530개 블로그 크롤링 완료\n",
      "540개 블로그 크롤링 완료\n",
      "550개 블로그 크롤링 완료\n",
      "560개 블로그 크롤링 완료\n",
      "570개 블로그 크롤링 완료\n",
      "580개 블로그 크롤링 완료\n"
     ]
    }
   ],
   "source": [
    "no_naver_blog1=[]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "time_list = [] #시간\n",
    "review_list = [] #리뷰\n",
    "comment_list = [] #댓글\n",
    "like_list = [] #좋아요수\n",
    "url_list = [] #url주소\n",
    "count = 0\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options) #크롬 드라이버 위치만 바꿔주시면 됩니다.\n",
    "for url in blog_url_list: #기본적으로 고치지 않으시지만, n번째 크롤링에서 멈췄다면, blog_url_list를 blog_url_list[n:]으로 고칩니다.\n",
    "    if 'naver' in url: #네이버 블로그만 수집(다른 사이트가 섞이면 크롤링 에러가 남)\n",
    "    \n",
    "        count += 1\n",
    "        driver.get(url) #url 하나씩 글을 수집할꺼야\n",
    "        time.sleep(1)\n",
    "\n",
    "        try:\n",
    "            # 전체 본문 가지고 와서\n",
    "            driver.switch_to.frame('mainFrame') #네이버는 mainFrame을 바꿔줘야 수집이 됌\n",
    "            time.sleep(1)\n",
    "        \n",
    "            soup = bs(driver.page_source, 'lxml') #뷰티풀숩을 이용해서 구문 분석(lxml 파싱 이용. 모든 테그에서 데이터를 추출위함)\n",
    "            postview = soup.find('div', attrs={'id': re.compile('post-view.+')}).get_text()\n",
    "\n",
    "            reg = re.compile(r'[\\s+]') #r은 raw string. \\s+는 공백문자\n",
    "            postview_reg = reg.sub(' ',postview) #공백을 띄어쓰기로 대치해서 본문 글 수집\n",
    "            try:\n",
    "                # 좋아요수\n",
    "                like = driver.find_element(\"xpath\", \"//span[@class='u_likeit_list_btn _button btn_sympathy pcol2 off']/em[@class='u_cnt _count']\")\n",
    "                like = like.text\n",
    "            except:\n",
    "                like = [] #좋아요 없으면 빈 리스트\n",
    "            \n",
    "            try:\n",
    "                timeline = driver.find_element(\"xpath\", \"//span[@class='se_publishDate pcol2']\") #수정 안 한 경우\n",
    "        \n",
    "            except:\n",
    "                timeline = driver.find_element(\"xpath\", \"//p[@class='date fil5 pcol2 _postAddDate']\") #수정 한 경우\n",
    "            timeline = timeline.text\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.CSS_SELECTOR,'span.btn_arr').click() #댓글 내리는 버튼(태그명.클래스선택자)\n",
    "                #driver.find_element_by_css_selector('span.btn_arr').click()\n",
    "                time.sleep(1.7)\n",
    "\n",
    "                comment_blog = []\n",
    "                comment = driver.find_element(By.CSS_SELECTOR,'span.u_cbox_contents') #댓글\n",
    "                #comment = driver.find_elements_by_css_selector('span.u_cbox_contents')\n",
    "                for i in comment: #댓글 수집\n",
    "                    com = str(i.text) #\n",
    "                    com = reg.sub(' ',com) \n",
    "                    comment_blog.append(([com]))\n",
    "            except: \n",
    "                comment_blog = []\n",
    "             \n",
    "            time_list.append(timeline)\n",
    "            review_list.append(postview_reg)\n",
    "            comment_list.append(comment_blog)\n",
    "            url_list.append(url)\n",
    "            like_list.append(like)\n",
    "            time.sleep(random.uniform(1,1.6))\n",
    "        except UnexpectedAlertPresentException:\n",
    "            pass\n",
    "    else:\n",
    "        no_naver_blog1.append(url)\n",
    "        print('네이버 블로그 아닌 url: ',url)\n",
    "        \n",
    "    if count%10 ==0:\n",
    "        print('{}개 블로그 크롤링 완료'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'time':time_list, 'review': review_list, 'comment':comment_list, 'like':like_list, 'url':url_list}\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "print('크롤링 소요 시간: ', time.time()-start)\n",
    "print('총 {}개 블로그 크롤링 완료'.format(count))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5768\\671444373.py:6: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "#블로그 주소 수집\n",
    "blog_url_list=[]\n",
    "#네이버에 키워드 검색\n",
    "for keyword in keyword_list:\n",
    "    url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=blog&query={}&oquery={}'.format(keyword, keyword)\n",
    "    driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)\n",
    "    driver.implicitly_wait(3)\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    #한번에 천개가 한계: 네이버 특성\n",
    "    url_want=990\n",
    "    \n",
    "    #검색 옵션 클릭\n",
    "    driver.find_element('xpath','//*[@id=\"snb\"]/div[1]/div/div[2]/a').click() \n",
    "\n",
    "    #날짜 지정\n",
    "    for k in range(len(first_days)):\n",
    "        try:\n",
    "            #시작과 끝의 년월일 설정\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[1]/a[9]/i').click() #직접 입력\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(first_days.year[k]-2002)).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(first_days.month[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(first_days.day[k])).click()\n",
    "\n",
    "\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[1]/span[3]/a').click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(last_days.year[k]-2002)).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(last_days.month[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(last_days.day[k])).click()\n",
    "            driver.find_element('xpath','//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[3]/button').click()\n",
    "\n",
    "            #스크롤 조작\n",
    "            last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "            #한페이지에 기본으로 30개 글이 나옴\n",
    "            scroll = (url_want/30)-1\n",
    "\n",
    "            #스크롤 다운\n",
    "            for i in range(int(scroll)):\n",
    "                driver.execute_script('window.scrollTo(0, document.body.scrollHeight')\n",
    "                time.sleep(random.uniform(1,1.7))\n",
    "\n",
    "                new_height=driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            soup = bs(driver.page_source, 'lxml')\n",
    "            blog_url = soup.find_all('a', class_='api_txt_lines total_tit')\n",
    "\n",
    "            #url 주소 수집\n",
    "            for i in blog_url:\n",
    "                #주소 수집\n",
    "                blog_url_list.append(i['href'])\n",
    "\n",
    "            print('{0} 키워드 {1}년 {2}월'.format(keyword, first_days.year[k], first_days.month[k]), len(blog_url), '개 블로그 url 주소 수집')\n",
    "\n",
    "            driver.execute_script('window.scrollTo(0,0)')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
